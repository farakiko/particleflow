{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df569247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import pickle as pkl\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from typing import Dict, List\n",
    "from torch_geometric.data import Batch, Data\n",
    "\n",
    "import vector, fastjet\n",
    "import awkward as ak\n",
    "\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "\n",
    "plt.style.use(hep.style.CMS)\n",
    "plt.rcParams.update({\"font.size\": 20})\n",
    "\n",
    "class print_color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edf87dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "16ca6a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant functions from mlpf.pyg\n",
    "import sys\n",
    "sys.path.append(\"/home/jovyan/particleflow/mlpf/\")\n",
    "import pyg\n",
    "sys.path.append(\"/home/jovyan/particleflow/mlpf/pyg/\")\n",
    "import utils\n",
    "\n",
    "from PFDataset import PFDataset, PFDataLoader, Collater\n",
    "\n",
    "from pyg.mlpf import MLPF\n",
    "from pyg.utils import X_FEATURES, Y_FEATURES, unpack_predictions, unpack_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14875b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use NVIDIA A100-SXM4-80GB\n"
     ]
    }
   ],
   "source": [
    "# define the global base device\n",
    "world_size = 1\n",
    "if torch.cuda.device_count():\n",
    "    rank = 0\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(f\"Will use {torch.cuda.get_device_name(device)}\")\n",
    "else:\n",
    "    rank = \"cpu\"\n",
    "    device = \"cpu\"\n",
    "    print(\"Will use cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f368fe",
   "metadata": {},
   "source": [
    "# Load the pre-trained MLPF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1879def6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint, model, optimizer=None):\n",
    "    if isinstance(model, torch.nn.parallel.DistributedDataParallel):\n",
    "        model.module.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    if optimizer:\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        return model, optimizer\n",
    "    else:\n",
    "        return model\n",
    "    \n",
    "    \n",
    "loaddir = \"/pfvol/experiments/MLPF_clic_A100_1gpu_pyg-clic_20240322_233518_004447\"\n",
    "\n",
    "with open(f\"{loaddir}/model_kwargs.pkl\", \"rb\") as f:\n",
    "    mlpf_kwargs = pkl.load(f)\n",
    "\n",
    "mlpf_kwargs[\"attention_type\"] = \"flash\"\n",
    "\n",
    "mlpf = MLPF(**mlpf_kwargs).to(torch.device(rank))\n",
    "checkpoint = torch.load(f\"{loaddir}/best_weights.pth\", map_location=torch.device(rank))\n",
    "\n",
    "mlpf = load_checkpoint(checkpoint, mlpf)\n",
    "mlpf.eval()\n",
    "\n",
    "print(mlpf)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde5f191",
   "metadata": {},
   "source": [
    "# CLIC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d98c6857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clic_edm_qq_pf\t\t   cms_pf_qcd_high_pt\t   cms_pf_single_proton\r\n",
      "clic_edm_ttbar_pf\t   cms_pf_single_electron  cms_pf_single_tau\r\n",
      "clic_edm_ttbar_pu10_pf\t   cms_pf_single_gamma\t   cms_pf_sms_t1tttt\r\n",
      "clic_edm_ww_fullhad_pf\t   cms_pf_single_mu\t   cms_pf_ttbar\r\n",
      "clic_edm_zh_tautau_pf\t   cms_pf_single_neutron   cms_pf_ztt\r\n",
      "cms_pf_multi_particle_gun  cms_pf_single_pi\t   delphes_qcd_pf\r\n",
      "cms_pf_qcd\t\t   cms_pf_single_pi0\t   delphes_ttbar_pf\r\n"
     ]
    }
   ],
   "source": [
    "! ls /pfvol/tensorflow_datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49d849e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['type',\n",
       " 'pt | et',\n",
       " 'eta',\n",
       " 'sin_phi',\n",
       " 'cos_phi',\n",
       " 'p | energy',\n",
       " 'chi2 | position.x',\n",
       " 'ndf | position.y',\n",
       " 'dEdx | position.z',\n",
       " 'dEdxError | iTheta',\n",
       " 'radiusOfInnermostHit | energy_ecal',\n",
       " 'tanLambda | energy_hcal',\n",
       " 'D0 | energy_other',\n",
       " 'omega | num_hits',\n",
       " 'Z0 | sigma_x',\n",
       " 'time | sigma_y',\n",
       " 'Null | sigma_z']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can see the 17th features here (recall type is 1 for tracks and 2 for clusters)\n",
    "X_FEATURES[\"clic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3781b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cls_id', 'charge', 'pt', 'eta', 'sin_phi', 'cos_phi', 'energy']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can see the 8 gen features per pf element here (notice the jet_index which may be useful)\n",
    "Y_FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d602e8e2",
   "metadata": {},
   "source": [
    "# Get the dataset (Events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "dfc6b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = \"/pfvol/tensorflow_datasets/\"\n",
    "data_dir = \"/home/jovyan/particleflow/tensorflow_datasets/\"\n",
    "sample = \"clic_edm_ttbar_pf\"\n",
    "\n",
    "dataset_train = PFDataset(data_dir, f\"{sample}:1.5.0\", \"train\", num_samples=10_000)\n",
    "dataset_test = PFDataset(data_dir, f\"{sample}:1.5.0\", \"test\", num_samples=10_000)\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "pad_3d = True\n",
    "train_loader = PFDataLoader(dataset_train.ds,\n",
    "                               batch_size=batch_size,\n",
    "                               collate_fn=Collater([\"X\", \"ygen\", \"ycand\"], pad_3d=pad_3d),\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "abf11cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 246, 17])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "\n",
    "    batch = batch.to(rank, non_blocking=True)\n",
    "    print(batch.X.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883675d2",
   "metadata": {},
   "source": [
    "# Pre-processing (Events -> Jets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "d22f4bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### set up forward hooks to retrive the latent representations of MLPF\n",
    "latent_reps = {}\n",
    "def get_activations(name):\n",
    "    def hook(mlpf, input, output):\n",
    "        latent_reps[name] = output.detach()\n",
    "\n",
    "    return hook\n",
    "\n",
    "mlpf.conv_reg[0].dropout.register_forward_hook(get_activations(\"conv_reg0\"))\n",
    "mlpf.conv_reg[1].dropout.register_forward_hook(get_activations(\"conv_reg1\"))\n",
    "mlpf.conv_reg[2].dropout.register_forward_hook(get_activations(\"conv_reg2\"))\n",
    "mlpf.nn_id.register_forward_hook(get_activations(\"nn_id\"))    \n",
    "###############################\n",
    "\n",
    "def get_latent_reps(batch, latent_reps):\n",
    "    for layer in latent_reps:\n",
    "        if \"conv\" in layer:\n",
    "            latent_reps[layer] *= batch.mask.unsqueeze(-1)\n",
    "\n",
    "    latentX = torch.cat(\n",
    "        [\n",
    "            batch.X.to(rank),\n",
    "            latent_reps[\"conv_reg0\"],\n",
    "            latent_reps[\"conv_reg1\"],\n",
    "            latent_reps[\"conv_reg2\"],\n",
    "            latent_reps[\"nn_id\"],\n",
    "        ],\n",
    "        axis=-1,\n",
    "    )\n",
    "    return latentX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "1bf42610",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [01:04<00:00,  1.55it/s]\n"
     ]
    }
   ],
   "source": [
    "sample_to_lab = {\n",
    "    \"clic_edm_ttbar_pf\": 1,\n",
    "}\n",
    "\n",
    "jetdef = fastjet.JetDefinition(fastjet.ee_genkt_algorithm, 0.7, -1.0)\n",
    "jet_ptcut=15.0\n",
    "jet_match_dr=0.1\n",
    "    \n",
    "for i, batch in enumerate(train_loader):\n",
    "    jet_dataset = []   # will save on disk at the end of the loop\n",
    "\n",
    "    batch = batch.to(rank, non_blocking=True)\n",
    "\n",
    "    # run the MLPF model in inference mode to get the MLPF cands / latent representations\n",
    "    with torch.no_grad():\n",
    "        with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16, enabled=True):\n",
    "            ymlpf = mlpf(batch.X, batch.mask)\n",
    "    ymlpf = unpack_predictions(ymlpf)\n",
    "    \n",
    "    # get the latent representations\n",
    "    ymlpf[\"latentX\"] = get_latent_reps(batch, latent_reps)\n",
    "\n",
    "    for k, v in ymlpf.items():\n",
    "        ymlpf[k] = v.detach().cpu()\n",
    "    \n",
    "    # cluster the jets using gen-level info\n",
    "    ygen = unpack_target(batch.ygen)    \n",
    "    vec = vector.awk(\n",
    "        ak.zip(\n",
    "            {\n",
    "                \"pt\": ygen[\"p4\"][:, :, 0].to(\"cpu\"),\n",
    "                \"eta\": ygen[\"p4\"][:, :, 1].to(\"cpu\"),\n",
    "                \"phi\": ygen[\"p4\"][:, :, 2].to(\"cpu\"),\n",
    "                \"e\": ygen[\"p4\"][:, :, 3].to(\"cpu\"),\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    cluster = fastjet.ClusterSequence(vec.to_xyzt(), jetdef)\n",
    "    gen_jet = cluster.inclusive_jets(min_pt=jet_ptcut)\n",
    "    genptcl_to_genjet_index = cluster.constituent_index(min_pt=jet_ptcut)\n",
    "\n",
    "    # build the big jet list\n",
    "    for iev in tqdm.tqdm(range(len(gen_jet_pt))):\n",
    "        \n",
    "        for ijet in range(len(gen_jet_pt[iev])):\n",
    "\n",
    "            if len(genptcl_to_genjet_index[iev][ijet])<3:   # don't save jets with very few particles\n",
    "                continue\n",
    "\n",
    "            # build a mask tensor that will select the particles that belong to the jet\n",
    "            msk_indices = genptcl_to_genjet_index[iev][ijet].to_numpy()\n",
    "            PADDIM = 256            \n",
    "            \n",
    "            jet_dataset += [\n",
    "            \n",
    "                dict(\n",
    "                    # Target for jet tagging\n",
    "                    jet_label=torch.tensor(sample_to_lab[sample]).unsqueeze(0),\n",
    "                    \n",
    "                    # Target for jet p4 regression                    \n",
    "                    jet_pt=torch.tensor(gen_jet.pt[iev][ijet]).unsqueeze(0),\n",
    "                    jet_eta=torch.tensor(gen_jet.eta[iev][ijet]).unsqueeze(0),\n",
    "                    jet_phi=torch.tensor(gen_jet.phi[iev][ijet]).unsqueeze(0),\n",
    "                    jet_energy=torch.tensor(gen_jet.energy[iev][ijet]).unsqueeze(0),\n",
    "\n",
    "                    # Input\n",
    "                    mlpfcands_momentum=torch.nn.functional.pad(\n",
    "                        ymlpf[\"momentum\"][iev][msk_indices],\n",
    "                        (0,0,0,PADDIM-ymlpf[\"momentum\"][iev][msk_indices].shape[0]),\n",
    "                        value=0,\n",
    "                    ),\n",
    "                    mlpfcands_pid=torch.nn.functional.pad(\n",
    "                        ymlpf[\"cls_id_onehot\"][iev][msk_indices],\n",
    "                        (0,0,0,PADDIM-ymlpf[\"cls_id_onehot\"][iev][msk_indices].shape[0]),\n",
    "                        value=0,\n",
    "                    ),\n",
    "                    mlpfcands_charge=torch.nn.functional.pad(\n",
    "                        ymlpf[\"charge\"][iev][msk_indices],\n",
    "                        (0,0,0,PADDIM-ymlpf[\"charge\"][iev][msk_indices].shape[0]),\n",
    "                        value=0,\n",
    "                    ),                    \n",
    "                    mlpfcands_latentX=torch.nn.functional.pad(\n",
    "                        ymlpf[\"latentX\"][iev][msk_indices],\n",
    "                        (0,0,0,PADDIM-ymlpf[\"latentX\"][iev][msk_indices].shape[0]),\n",
    "                        value=0,\n",
    "                    )\n",
    "                )\n",
    "            ]    \n",
    "            \n",
    "#             break  # per jet\n",
    "#         break   # per event\n",
    "\n",
    "    torch.save(jet_dataset, f\"/pfvol/jetdataset/{sample}/train/{i}.pt\")\n",
    "\n",
    "    break    # per batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543e188a",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "8b756453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.pt\r\n"
     ]
    }
   ],
   "source": [
    "! ls /pfvol/jetdataset/clic_edm_ttbar_pf/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "b312f809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load one of the train files\n",
    "jet_dataset = torch.load(\"/pfvol/jetdataset/clic_edm_ttbar_pf/train/0.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "0be6db7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['jet_label', 'jet_pt', 'jet_eta', 'jet_phi', 'jet_energy', 'mlpfcands_momentum', 'mlpfcands_pid', 'mlpfcands_charge', 'mlpfcands_latentX'])"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jet_dataset[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "2f403898",
   "metadata": {},
   "outputs": [],
   "source": [
    "jetloader = torch.utils.data.dataloader.DataLoader(jet_dataset, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "febda66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in jetloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "c3c80e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22.4181],\n",
       "        [23.0416],\n",
       "        [27.6135],\n",
       "        [62.2044],\n",
       "        [65.7092],\n",
       "        [52.7170],\n",
       "        [21.0416],\n",
       "        [62.5815],\n",
       "        [56.3452],\n",
       "        [80.0007]], dtype=torch.float64)"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"jet_pt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92a5d20",
   "metadata": {},
   "source": [
    "# Setup the downstream task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "47af16a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def ffn(input_dim, output_dim, width, act, dropout):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, width),\n",
    "        act(),\n",
    "        torch.nn.LayerNorm(width),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(width, output_dim),\n",
    "    )\n",
    "\n",
    "class JetRegressor(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim=14,\n",
    "        output_dim=1,\n",
    "        width=256,\n",
    "        dropout=0,\n",
    "    ):\n",
    "        super(JetRegressor, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        Takes as input either (1) the MLPF candidates OR (2) the latent representations of the MLPF candidates,\n",
    "        and runs an MLP to predict an output per candidate: \"w_i\"; which will enter the loss as follows:\n",
    "            pred_jetpt = sum(w_i * pti)\n",
    "\n",
    "            LOSS = Huber(true_jetpt, pred_jetpt)\n",
    "\n",
    "        Note: default `input_dim` is 14 which stands for \"clf_nodes (6) + charge_nodes (3) + regression_nodes (5)\"\n",
    "        \"\"\"\n",
    "\n",
    "        self.act = nn.ELU\n",
    "        self.nn = ffn(input_dim, output_dim, width, self.act, dropout)\n",
    "\n",
    "    # @torch.compile\n",
    "    def forward(self, X):\n",
    "\n",
    "        jetpt = self.nn(X)\n",
    "\n",
    "        return jetpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "6a897501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JetRegressor(\n",
       "  (nn): Sequential(\n",
       "    (0): Linear(in_features=791, out_features=256, bias=True)\n",
       "    (1): ELU(alpha=1.0)\n",
       "    (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): Dropout(p=0, inplace=False)\n",
       "    (4): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_with_latentX = True\n",
    "\n",
    "if run_with_latentX:\n",
    "    input_dim = 791\n",
    "else:\n",
    "    input_dim = 14    \n",
    "    \n",
    "model = JetRegressor(input_dim).to(rank)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "9dcaa522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 256, 1])"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in jetloader:\n",
    "\n",
    "    if run_with_latentX:\n",
    "        X = batch[\"mlpfcands_latentX\"].to(rank)\n",
    "    else:\n",
    "        X = torch.cat([batch[\"mlpfcands_momentum\"], batch[\"mlpfcands_pid\"], batch[\"mlpfcands_charge\"]], axis=-1).to(rank)\n",
    "    \n",
    "    out = model(X).\n",
    "    \n",
    "    break\n",
    "out.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
