{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "df569247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "import pickle as pkl\n",
    "import time\n",
    "from typing import Dict, List\n",
    "\n",
    "import awkward as ak\n",
    "import fastjet\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "import tqdm\n",
    "import vector\n",
    "from torch_geometric.data import Batch, Data\n",
    "\n",
    "plt.style.use(hep.style.CMS)\n",
    "plt.rcParams.update({\"font.size\": 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edf87dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "16ca6a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant functions from mlpf.pyg\n",
    "import sys\n",
    "sys.path.append(\"/home/jovyan/particleflow/mlpf/\")\n",
    "import pyg\n",
    "sys.path.append(\"/home/jovyan/particleflow/mlpf/pyg/\")\n",
    "import utils\n",
    "\n",
    "from PFDataset import PFDataset, PFDataLoader, Collater\n",
    "\n",
    "from pyg.mlpf import MLPF\n",
    "from pyg.utils import X_FEATURES, Y_FEATURES, unpack_predictions, unpack_target\n",
    "from jet_utils import match_two_jet_collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14875b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use NVIDIA A100-SXM4-80GB\n"
     ]
    }
   ],
   "source": [
    "# define the global base device\n",
    "world_size = 1\n",
    "if torch.cuda.device_count():\n",
    "    rank = 0\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(f\"Will use {torch.cuda.get_device_name(device)}\")\n",
    "else:\n",
    "    rank = \"cpu\"\n",
    "    device = \"cpu\"\n",
    "    print(\"Will use cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bca0ec5",
   "metadata": {},
   "source": [
    "# Load the pre-trained MLPF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1879def6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint, model, optimizer=None):\n",
    "    if isinstance(model, torch.nn.parallel.DistributedDataParallel):\n",
    "        model.module.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    if optimizer:\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        return model, optimizer\n",
    "    else:\n",
    "        return model\n",
    "    \n",
    "    \n",
    "loaddir = \"/pfvol/experiments/MLPF_clic_A100_1gpu_pyg-clic_20240322_233518_004447\"\n",
    "\n",
    "with open(f\"{loaddir}/model_kwargs.pkl\", \"rb\") as f:\n",
    "    mlpf_kwargs = pkl.load(f)\n",
    "\n",
    "mlpf_kwargs[\"attention_type\"] = \"flash\"\n",
    "\n",
    "mlpf = MLPF(**mlpf_kwargs).to(torch.device(rank))\n",
    "checkpoint = torch.load(f\"{loaddir}/best_weights.pth\", map_location=torch.device(rank))\n",
    "\n",
    "mlpf = load_checkpoint(checkpoint, mlpf)\n",
    "mlpf.eval()\n",
    "\n",
    "print(mlpf)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde5f191",
   "metadata": {},
   "source": [
    "# CLIC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d98c6857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clic_edm_qq_pf\t\t   cms_pf_qcd_high_pt\t   cms_pf_single_proton\r\n",
      "clic_edm_ttbar_pf\t   cms_pf_single_electron  cms_pf_single_tau\r\n",
      "clic_edm_ttbar_pu10_pf\t   cms_pf_single_gamma\t   cms_pf_sms_t1tttt\r\n",
      "clic_edm_ww_fullhad_pf\t   cms_pf_single_mu\t   cms_pf_ttbar\r\n",
      "clic_edm_zh_tautau_pf\t   cms_pf_single_neutron   cms_pf_ztt\r\n",
      "cms_pf_multi_particle_gun  cms_pf_single_pi\t   delphes_qcd_pf\r\n",
      "cms_pf_qcd\t\t   cms_pf_single_pi0\t   delphes_ttbar_pf\r\n"
     ]
    }
   ],
   "source": [
    "! ls /pfvol/tensorflow_datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49d849e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['type',\n",
       " 'pt | et',\n",
       " 'eta',\n",
       " 'sin_phi',\n",
       " 'cos_phi',\n",
       " 'p | energy',\n",
       " 'chi2 | position.x',\n",
       " 'ndf | position.y',\n",
       " 'dEdx | position.z',\n",
       " 'dEdxError | iTheta',\n",
       " 'radiusOfInnermostHit | energy_ecal',\n",
       " 'tanLambda | energy_hcal',\n",
       " 'D0 | energy_other',\n",
       " 'omega | num_hits',\n",
       " 'Z0 | sigma_x',\n",
       " 'time | sigma_y',\n",
       " 'Null | sigma_z']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can see the 17th features here (recall type is 1 for tracks and 2 for clusters)\n",
    "X_FEATURES[\"clic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3781b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cls_id', 'charge', 'pt', 'eta', 'sin_phi', 'cos_phi', 'energy']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can see the 8 gen features per pf element here (notice the jet_index which may be useful)\n",
    "Y_FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d602e8e2",
   "metadata": {},
   "source": [
    "# Get the dataset (Events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "dfc6b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/jovyan/particleflow/tensorflow_datasets/\"\n",
    "sample = \"clic_edm_ttbar_pf\"\n",
    "\n",
    "dataset_train = PFDataset(data_dir, f\"{sample}:1.5.0\", \"train\", num_samples=10_000)\n",
    "\n",
    "batch_size = 100\n",
    "pad_3d = True\n",
    "train_loader = PFDataLoader(dataset_train.ds,\n",
    "                               batch_size=batch_size,\n",
    "                               collate_fn=Collater([\"X\", \"ygen\", \"ycand\"], pad_3d=pad_3d),\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "abf11cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 246, 17])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    batch = batch.to(rank, non_blocking=True)\n",
    "    break\n",
    "print(batch.X.shape)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883675d2",
   "metadata": {},
   "source": [
    "# Pre-processing (Events -> Jets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "d22f4bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### set up forward hooks to retrive the latent representations of MLPF\n",
    "latent_reps = {}\n",
    "def get_activations(name):\n",
    "    def hook(mlpf, input, output):\n",
    "        latent_reps[name] = output.detach()\n",
    "\n",
    "    return hook\n",
    "\n",
    "mlpf.conv_reg[0].dropout.register_forward_hook(get_activations(\"conv_reg0\"))\n",
    "mlpf.conv_reg[1].dropout.register_forward_hook(get_activations(\"conv_reg1\"))\n",
    "mlpf.conv_reg[2].dropout.register_forward_hook(get_activations(\"conv_reg2\"))\n",
    "mlpf.nn_id.register_forward_hook(get_activations(\"nn_id\"))    \n",
    "###############################\n",
    "\n",
    "def get_latent_reps(batch, latent_reps):\n",
    "    for layer in latent_reps:\n",
    "        if \"conv\" in layer:\n",
    "            latent_reps[layer] *= batch.mask.unsqueeze(-1)\n",
    "\n",
    "    latentX = torch.cat(\n",
    "        [\n",
    "            batch.X.to(rank),\n",
    "            latent_reps[\"conv_reg0\"],\n",
    "            latent_reps[\"conv_reg1\"],\n",
    "            latent_reps[\"conv_reg2\"],\n",
    "            latent_reps[\"nn_id\"],\n",
    "        ],\n",
    "        axis=-1,\n",
    "    )\n",
    "    return latentX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "1bf42610",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:39<00:00,  2.50it/s]\n"
     ]
    }
   ],
   "source": [
    "sample_to_lab = {\n",
    "    \"clic_edm_ttbar_pf\": 1,\n",
    "    \"clic_edm_qq_pf\": 0,   \n",
    "}\n",
    "\n",
    "jetdef = fastjet.JetDefinition(fastjet.ee_genkt_algorithm, 0.7, -1.0)\n",
    "jet_ptcut = 15.0\n",
    "jet_match_dr = 0.1\n",
    "    \n",
    "for i, batch in enumerate(train_loader):\n",
    "    # initilize - will save on disk at the end of the loop\n",
    "    jet_dataset = []\n",
    "\n",
    "    # run the MLPF model in inference mode to get the MLPF cands / latent representations    \n",
    "    batch = batch.to(rank, non_blocking=True)\n",
    "    with torch.no_grad():\n",
    "        with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16, enabled=True):\n",
    "            ymlpf = mlpf(batch.X, batch.mask)\n",
    "    ymlpf = unpack_predictions(ymlpf)\n",
    "    \n",
    "    # get the latent representations\n",
    "    ymlpf[\"latentX\"] = get_latent_reps(batch, latent_reps)\n",
    "\n",
    "    for k, v in ymlpf.items():\n",
    "        ymlpf[k] = v.detach().cpu()\n",
    "    \n",
    "    jets_coll = {}\n",
    "    ####################### get the reco jet collection\n",
    "    vec = vector.awk(\n",
    "        ak.zip(\n",
    "            {\n",
    "                \"pt\": ymlpf[\"p4\"][:, :, 0].to(\"cpu\"),\n",
    "                \"eta\": ymlpf[\"p4\"][:, :, 1].to(\"cpu\"),\n",
    "                \"phi\": ymlpf[\"p4\"][:, :, 2].to(\"cpu\"),\n",
    "                \"e\": ymlpf[\"p4\"][:, :, 3].to(\"cpu\"),\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    cluster = fastjet.ClusterSequence(vec.to_xyzt(), jetdef)\n",
    "    jets_coll[\"reco\"] = cluster.inclusive_jets(min_pt=jet_ptcut)\n",
    "    #######################    \n",
    "    \n",
    "    ####################### get the gen jet collection\n",
    "    ygen = unpack_target(batch.ygen)    \n",
    "    vec = vector.awk(\n",
    "        ak.zip(\n",
    "            {\n",
    "                \"pt\": ygen[\"p4\"][:, :, 0].to(\"cpu\"),\n",
    "                \"eta\": ygen[\"p4\"][:, :, 1].to(\"cpu\"),\n",
    "                \"phi\": ygen[\"p4\"][:, :, 2].to(\"cpu\"),\n",
    "                \"e\": ygen[\"p4\"][:, :, 3].to(\"cpu\"),\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    cluster = fastjet.ClusterSequence(vec.to_xyzt(), jetdef)\n",
    "    jets_coll[\"gen\"] = cluster.inclusive_jets(min_pt=jet_ptcut)\n",
    "    #######################\n",
    "    \n",
    "    matched_jets = match_two_jet_collections(jets_coll, \"reco\", \"gen\", jet_match_dr)\n",
    "    \n",
    "    # get the constituents to mask the MLPF candidates and build the input for the downstream\n",
    "    genptcl_to_genjet_index = cluster.constituent_index(min_pt=jet_ptcut)    \n",
    "    \n",
    "    # build the big jet list\n",
    "    for iev in tqdm.tqdm(range(len(matched_jets[\"gen\"]))):\n",
    "        \n",
    "        num_matched_jets = len(matched_jets[\"gen\"][iev])   # number of gen jets matched to reco\n",
    "        \n",
    "        for ijet in range(num_matched_jets):   \n",
    "            igenjet = matched_jets[\"gen\"][iev][ijet]\n",
    "            irecojet = matched_jets[\"reco\"][iev][ijet]\n",
    "\n",
    "            if len(genptcl_to_genjet_index[iev][igenjet])<3:   # don't save jets with very few particles\n",
    "                continue\n",
    "\n",
    "            # build a mask tensor that will select the particles that belong to the gen jet\n",
    "            msk_indices = genptcl_to_genjet_index[iev][igenjet].to_numpy()\n",
    "            PADDIM = 256            \n",
    "\n",
    "            jet_dataset += [\n",
    "\n",
    "                dict(\n",
    "                    # Target for jet tagging\n",
    "                    gen_jet_label=torch.tensor(sample_to_lab[sample]).unsqueeze(0),\n",
    "                    \n",
    "                    # Target for jet p4 regression                    \n",
    "                    gen_jet_pt=torch.tensor(jets_coll[\"gen\"][iev][igenjet].pt).unsqueeze(0),\n",
    "                    gen_jet_eta=torch.tensor(jets_coll[\"gen\"][iev][igenjet].eta).unsqueeze(0),\n",
    "                    gen_jet_phi=torch.tensor(jets_coll[\"gen\"][iev][igenjet].phi).unsqueeze(0),\n",
    "                    gen_jet_energy=torch.tensor(jets_coll[\"gen\"][iev][igenjet].energy).unsqueeze(0),\n",
    "\n",
    "                    # could be part of the target\n",
    "                    reco_jet_pt=torch.tensor(jets_coll[\"reco\"][iev][irecojet].pt).unsqueeze(0),\n",
    "                    reco_jet_eta=torch.tensor(jets_coll[\"reco\"][iev][irecojet].eta).unsqueeze(0),\n",
    "                    reco_jet_phi=torch.tensor(jets_coll[\"reco\"][iev][irecojet].phi).unsqueeze(0),\n",
    "                    reco_jet_energy=torch.tensor(jets_coll[\"reco\"][iev][irecojet].energy).unsqueeze(0),\n",
    "\n",
    "                    # Input\n",
    "                    mlpfcands_momentum=torch.nn.functional.pad(\n",
    "                        ymlpf[\"momentum\"][iev][msk_indices],\n",
    "                        (0,0,0,PADDIM-ymlpf[\"momentum\"][iev][msk_indices].shape[0]),\n",
    "                        value=0,\n",
    "                    ),\n",
    "                    mlpfcands_pid=torch.nn.functional.pad(\n",
    "                        ymlpf[\"cls_id_onehot\"][iev][msk_indices],\n",
    "                        (0,0,0,PADDIM-ymlpf[\"cls_id_onehot\"][iev][msk_indices].shape[0]),\n",
    "                        value=0,\n",
    "                    ),\n",
    "                    mlpfcands_charge=torch.nn.functional.pad(\n",
    "                        ymlpf[\"charge\"][iev][msk_indices],\n",
    "                        (0,0,0,PADDIM-ymlpf[\"charge\"][iev][msk_indices].shape[0]),\n",
    "                        value=0,\n",
    "                    ),                    \n",
    "                    mlpfcands_latentX=torch.nn.functional.pad(\n",
    "                        ymlpf[\"latentX\"][iev][msk_indices],\n",
    "                        (0,0,0,PADDIM-ymlpf[\"latentX\"][iev][msk_indices].shape[0]),\n",
    "                        value=0,\n",
    "                    )\n",
    "                )\n",
    "            ]    \n",
    "\n",
    "#             break  # per jet\n",
    "#         break   # per event\n",
    "\n",
    "    torch.save(jet_dataset, f\"/pfvol/jetdataset/{sample}/train/{i}.pt\")\n",
    "\n",
    "    break    # per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "4f3845f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['gen_jet_label', 'gen_jet_pt', 'gen_jet_eta', 'gen_jet_phi', 'gen_jet_energy', 'reco_jet_pt', 'reco_jet_eta', 'reco_jet_phi', 'reco_jet_energy', 'mlpfcands_momentum', 'mlpfcands_pid', 'mlpfcands_charge', 'mlpfcands_latentX'])"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jet_dataset[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543e188a",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "5e7ac78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271M\t/pfvol/jetdataset/clic_edm_ttbar_pf/train/0.pt\r\n"
     ]
    }
   ],
   "source": [
    "! du -sh /pfvol/jetdataset/clic_edm_ttbar_pf/train/0.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "9301a176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load one of the train files\n",
    "jet_dataset = torch.load(\"/pfvol/jetdataset/clic_edm_ttbar_pf/train/0.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "0be6db7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['gen_jet_label', 'gen_jet_pt', 'gen_jet_eta', 'gen_jet_phi', 'gen_jet_energy', 'reco_jet_pt', 'reco_jet_eta', 'reco_jet_phi', 'reco_jet_energy', 'mlpfcands_momentum', 'mlpfcands_pid', 'mlpfcands_charge', 'mlpfcands_latentX'])"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jet_dataset[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "a7565179",
   "metadata": {},
   "outputs": [],
   "source": [
    "jetloader = torch.utils.data.dataloader.DataLoader(jet_dataset, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "050eef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in jetloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "834f55f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22.4181],\n",
       "        [23.0416],\n",
       "        [27.6135],\n",
       "        [62.2044],\n",
       "        [21.0416],\n",
       "        [52.7170],\n",
       "        [62.5815],\n",
       "        [56.3452],\n",
       "        [80.0007],\n",
       "        [29.5156]], dtype=torch.float64)"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"gen_jet_pt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "31f4b445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[23.6038],\n",
       "        [24.1894],\n",
       "        [34.3942],\n",
       "        [66.5854],\n",
       "        [21.3737],\n",
       "        [59.5791],\n",
       "        [70.3020],\n",
       "        [59.1744],\n",
       "        [82.2939],\n",
       "        [30.3395]], dtype=torch.float64)"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"reco_jet_pt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12df2ae6",
   "metadata": {},
   "source": [
    "# Setup the downstream task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "6f05dc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def ffn(input_dim, output_dim, width, act, dropout):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, width),\n",
    "        act(),\n",
    "        torch.nn.LayerNorm(width),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(width, output_dim),\n",
    "    )\n",
    "\n",
    "class JetRegressor(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim=14,\n",
    "        embedding_dim=64,\n",
    "        output_dim=1,\n",
    "        width=256,\n",
    "        dropout=0,\n",
    "    ):\n",
    "        super(JetRegressor, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        Takes as input either (1) the MLPF candidates OR (2) the latent representations of the MLPF candidates,\n",
    "        and runs an MLP to predict an output per jet: \"ptcorr\"; which will enter the loss as follows:\n",
    "            pred_jetpt = ptcorr * reco_pt\n",
    "\n",
    "            LOSS = Huber(true_jetpt, pred_jetpt)\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.act = nn.ELU\n",
    "        self.nn1 = ffn(input_dim, embedding_dim, width, self.act, dropout)\n",
    "        self.nn2 = ffn(embedding_dim, output_dim, width, self.act, dropout)\n",
    "\n",
    "    # @torch.compile\n",
    "    def forward(self, X):\n",
    "\n",
    "        embeddings = self.nn1(X)\n",
    "        \n",
    "        pooled_embeddings = embeddings.sum(axis=1)   # recall ~ [Batch, Particles, Features]\n",
    "\n",
    "        return self.nn2(pooled_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "45ddd082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JetRegressor(\n",
       "  (nn1): Sequential(\n",
       "    (0): Linear(in_features=791, out_features=256, bias=True)\n",
       "    (1): ELU(alpha=1.0)\n",
       "    (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): Dropout(p=0, inplace=False)\n",
       "    (4): Linear(in_features=256, out_features=64, bias=True)\n",
       "  )\n",
       "  (nn2): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (1): ELU(alpha=1.0)\n",
       "    (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): Dropout(p=0, inplace=False)\n",
       "    (4): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_with_latentX = True\n",
    "\n",
    "if run_with_latentX:\n",
    "    input_dim = 791\n",
    "else:\n",
    "    input_dim = 14    \n",
    "    \n",
    "model = JetRegressor(input_dim).to(rank)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "e2e8f3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0240, dtype=torch.float64, grad_fn=<HuberLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for batch in jetloader:\n",
    "\n",
    "    if run_with_latentX:\n",
    "        X = batch[\"mlpfcands_latentX\"].to(rank)\n",
    "    else:\n",
    "        X = torch.cat([batch[\"mlpfcands_momentum\"], batch[\"mlpfcands_pid\"], batch[\"mlpfcands_charge\"]], axis=-1).to(rank)\n",
    "    \n",
    "    ptcorr = model(X).cpu()\n",
    "    \n",
    "    target = torch.log(batch[\"gen_jet_pt\"] / batch[\"reco_jet_pt\"])\n",
    "\n",
    "    loss = torch.nn.functional.huber_loss(target, ptcorr)\n",
    "    \n",
    "    break\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e06db9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
